{
  "hash": "a4da9bb8d56fb5c50ffcbe50dd9eb9a7",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Linear Regression via MLE\"\nsubtitle: \"Basic MLE-Programming and margins\"\nformat: html\n---\n\n## Introduction\n\n`Stata` has a very useful command that can be used for the estimation of almost any linear and nonlinear models using maximum likelihood. This command is -ml-.\n\nProperly speaking, this command can be used to obtain M-type estimators, however, I'll concentrate on maximum likelihood models.\n\nIn this small tutorial, I'll provide a small example of how to use -ml- in combination with -margins- to estimate marginal effects for a linear model, as long as one identifies the outcome of interest.\n\n## LR as MLE\n\nAs I mentioned earlier, the `ml` command in Stata is a powerful tool for obtaining maximum likelihood estimators, although it can be used to find solutions for any m-type estimators. The one limitation I have encountered with this command is that it can be resource-intensive when estimating complex models on large datasets. For instance, If you have a dataset with one million observations but only use 10% of it for modeling, dropping the unused data before estimation can speed up the process. `ml` will not do that for you.\n\nThere are several ways to program `ml`, such as using the lf, df0, df1, or df2 options. The main difference among them is that you must define the objective function, its gradient, and its Hessian. However, for most purposes, I find that `lf` is the only one you will ever need.\n\nWhen using `ml` with the `lf` option, you only need to declare the loglikelihood function contributed by each observation in the sample. To illustrate this concept, let's assume that we want to estimate a simple linear regression using MLE. For this, we need to assume that either the error follows a normal distribution or that the outcome follows a conditionally normal distribution.\n\n$$\n\\begin{aligned}\ny_i &= X_i'\\beta + e_i \\\\\ne_i &\\sim N(0,\\sigma^2) \\ or \\ y_i \\sim N(X_i'\\beta,sigma^2)\n\\end{aligned}\n$$\n\nThis implies that the Likelihood ($L_i$)  and Log-Likelihood ($LL_i$) of a single observation is given by:\n$$\n\\begin{aligned}\nL_i &= \\frac{1}{\\sigma \\sqrt{2\\pi}} exp\\left( -\\frac{1}{2} \\left(\\frac{y_i -X_i'\\beta }{\\sigma} \\right)^2 \\right) \\\\\nLL_i &= -log(\\sigma) - \\frac{1}{2} log (2\\pi) -\\frac{1}{2} \\left(\\frac{y_i -X_i'\\beta }{\\sigma} \\right)^2\n\\end{aligned} \n$$\n\nSo we just need to create a program that defines this log-likelihood function. \n\n::: {#73416341 .cell execution_count=1}\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<style>div.jp-Notebook .datagrid-container {min-height: 448px; }</style>\n```\n:::\n:::\n\n\n::: {#9afe5d28 .cell execution_count=2}\n``` {.stata .cell-code code-fold=\"false\" code-line-numbers=\"true\"}\nprogram myols_mle\n    args lnf xb lnsigma\n    local sigma exp(`lnsigma')\n    *qui:replace `lnf' = -`lnsigma' - 1/2 * log(2*_pi) - 1/2 *(($ML_y1-`xb')/`sigma')^2\n    qui: replace `lnf' = log(normalden($ML_y1,`xb',`sigma'))\nend\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n```\n:::\n:::\n\n\nNotice that this program has 3 arguments (which come after `args`) (see line 2)\n\n- `lnf`: Will store the log-Likelihood for each observation\n- `xb`: Will store the linear combination of variables and their coefficients\n- `lnsigma`: Will store the $log(\\sigma)$. \n\nWe do not estimate $\\sigma$ directly, because its numerically more stable to estimate the $log(\\sigma)$. Also, we require $\\sigma$\nto be strictly positive, which can only be done by using the log transformation.\n\nIn line 3, I specifically impose the transformation to obtain $\\sigma$. \n\nIn line 4, I leave the comment of how I would write the full Loglikelihood using the formula I provided before, but for simplicilty \nI use the built-in `normalden` (line 5)\n\nYou should also notice that all arguments will be handled internally as `locals`, which is why they need to be written within single quotes: `' . The only exception is `$ML_y1`, which represents the dependent variable.\n\n## Programming for Margins\n\nThe second component I'm interested in introducing today is to create a program that will allow you to modify how `margins`, operate.\n\nAs some may know, `margins` is a `Stata` built-in program that estimates marginal effects, or marginal means, for any official and unofficial model in `Stata`.\nThe way it works is rather simple. Once you estimat you model of interest and call on margins it will:\n\n1. Estimate the predicted outcome for the model. This varies by model, but the default is to use the linear combination of variables and coefficients.\n\n2. Depending on other modeling factors, estimate derivatives, or means, of the outcome with respect to every variable in the model.\n\n3. Calculate standard errors using Delta method, and summarize results.\n\nSteps 2 and 3 above are common to all models. However, step 1 is the one that needs to be modified everytime one changes from one model to another.\n\nWhat I will do next is to write a program where I will define different types of outcomes that I may be interested in when analyzing Linear regressions. I will call this program `myols_mle_p`, following `Stata` naming standards:\n\n::: {#18de00e8 .cell execution_count=3}\n``` {.stata .cell-code code-fold=\"false\" code-line-numbers=\"true\"}\nprogram myols_mle_p\n    syntax newvarname [if] [in] , [ mean sigma emean *]\n    if \"`mean'`sigma'`emean'\" ==\"\" {\n        ml_p `0'\n    }\n    marksample touse, novarlist\n    if \"`mean'\" !=\"\"  {\n        tempvar xb\n        _predict double `xb' , eq(#1)\n        gen `typlist' `varlist' = `xb' if `touse'\n        label var `varlist' \"E(y|X)\"\n    }\n    else if \"`sigma'\" !=\"\"  {\n        tempvar xb\n        _predict double `xb' , eq(#2)\n        gen `typlist' `varlist' = exp(`xb') if `touse'\n        label var `varlist' \"E(sigma|X)\"\n    }\n    else if \"`emean'\"!=\"\" {\n        tempvar xb lns\n        _predict double `xb' , eq(#1)\n        _predict double `lns' , eq(#2)\n        local sigma (exp(`lns'))\n        gen `typlist' `varlist' = exp(`xb')*exp(0.5*`sigma'^2) if `touse'\n        label var `varlist' \"E(exp(Y)|X)\"\n    }\nend\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n```\n:::\n:::\n\n\nThe way I'm defining this program, one could request 3 types of outcomes:\n\n- `mean`: This is the standard outcome. Just looking into the linear combination of X and betas\n- `sigma`: When this option is used, you will obtain the prediction for $\\sigma$ instead of $log(\\sigma)$. May be useful to compare and test heteroskedasticity directly\n- `emean`: This is something different. This option could be used if your outcome of interest was \"wages\", but you were modeling \"log(wages)\". This will be estimated under the assumption of log-normality.\n\nIf neither option is used, it will revert to use the default.\n\n## The Estimation\n\nBefore we estimate the LR model using MLE, lets start by loading some data: \n\n::: {#fbedc495 .cell execution_count=4}\n``` {.stata .cell-code code-fold=\"false\"}\nfrause oaxaca, clear\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n(Excerpt from the Swiss Labor Market Survey 1998)\n```\n:::\n:::\n\n\nNow, to estimate a model using -ml-, we need to use a somewhat complex syntax, that would be better explained in the following code:\n\n```stata\nml model lf myols_mle /// \n   (mean:lnwage = educ exper i.female) ///\n   (ln_sigma:  = educ exper i.female) ///\n   , maximize  nolog\nml display   \n```\n\nLine 1. Indicates you will try and estimate a model using `ml`, where the model will use `lf` option (which only requires the log-likelihood function at individual level to be provided. You also need to provide the name of the program that defines the LL function: `myols_mle`.\n\nLine 2 and 3. As described earlier, the program `myols_mle` requires 3 arguments. The first one is the LL function, so we do not need to be concernd about. The other two arguments refer to `xb` or conditional mean, and `lnsigma` or log of the variance, need to be declared here. They are order specific. Line 2 will always refer to `xb`, independent of the name I provide, and Line 3 will always refer to `lnsigma`. \n\nIn standard models, we assume homoskedasticity, so we do not need to add covariates to `lnsigma`, but we can do it and control for heteroskedasticity directly.\n\nIn line 4, I simply request model to be maximized, but could just as well requested clustered standard errors, or use other options allowed in `ml`.\n\nFinally line 5 request displaying the results. So lets see what we get:\n\n```stata\n\n                                                        Number of obs =  1,434\n                                                        Wald chi2(3)  = 371.53\nLog likelihood = -871.18998                             Prob > chi2   = 0.0000\n\n------------------------------------------------------------------------------\n      lnwage | Coefficient  Std. err.      z    P>|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\nmean         |\n        educ |   .0736371   .0045872    16.05   0.000     .0646464    .0826278\n       exper |   .0105825   .0010551    10.03   0.000     .0085147    .0126504\n    1.female |  -.1118167    .024106    -4.64   0.000    -.1590636   -.0645698\n       _cons |   2.430164   .0641158    37.90   0.000     2.304499    2.555828\n-------------+----------------------------------------------------------------\nln_sigma     |\n        educ |  -.0356134   .0067794    -5.25   0.000    -.0489008   -.0223259\n       exper |  -.0165439   .0016363   -10.11   0.000     -.019751   -.0133368\n    1.female |   .2066704   .0382432     5.40   0.000     .1317152    .2816256\n       _cons |  -.2813734   .0910696    -3.09   0.002    -.4598665   -.1028802\n------------------------------------------------------------------------------\n```\n\n\nYou can compare these results with the standard `regress` outcome, or `hetregress` if you want to compare the results allowing for heteroskedastic errors.\n\n\n## `margins` \n\nMargins can be used here to analyze the effect of covariates on the outcome of interest. The default from -ml- is to use linear combinations of coefficients and covariates. Now, if we want to use our predict command, we need to modify one piece of information in e(). If you type `ereturn list`, after every `Stata` command, you will see there is one local named `e(predict)`. This local has the name of a program that is used to get predictions for a given model. We need to modify it, and change the default name to our program: `myols_mle_p`. \n\nWe will do this with the following program:\n\n::: {#0636e396 .cell execution_count=6}\n``` {.stata .cell-code code-fold=\"false\"}\nprogram adde, eclass\n    ereturn `0'\nend\nadde local predict myols_mle_p\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n```\n:::\n:::\n\n\nOk with all of this, we are ready to estimate marginal effects. The next two lines should give you the same result, \nbut I present them here as an example:\n\n::: {#a7222b66 .cell execution_count=7}\n``` {.stata .cell-code code-fold=\"false\"}\nmargins, dydx(*)\nmargins, dydx(*) predict(mean)  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nAverage marginal effects                                 Number of obs = 1,434\nModel VCE: OIM\n\nExpression: Linear prediction, predict()\ndy/dx wrt:  educ exper 1.female\n\n------------------------------------------------------------------------------\n             |            Delta-method\n             |      dy/dx   std. err.      z    P>|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        educ |   .0736371   .0045872    16.05   0.000     .0646464    .0826278\n       exper |   .0105825   .0010551    10.03   0.000     .0085147    .0126504\n    1.female |  -.1118167    .024106    -4.64   0.000    -.1590636   -.0645698\n------------------------------------------------------------------------------\nNote: dy/dx for factor levels is the discrete change from the base level.\n\nAverage marginal effects                                 Number of obs = 1,434\nModel VCE: OIM\n\nExpression: E(y|X), predict(mean)\ndy/dx wrt:  educ exper 1.female\n\n------------------------------------------------------------------------------\n             |            Delta-method\n             |      dy/dx   std. err.      z    P>|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        educ |   .0736371   .0045872    16.05   0.000     .0646464    .0826278\n       exper |   .0105825   .0010551    10.03   0.000     .0085147    .0126504\n    1.female |  -.1118167    .024106    -4.64   0.000    -.1590636   -.0645698\n------------------------------------------------------------------------------\nNote: dy/dx for factor levels is the discrete change from the base level.\n```\n:::\n:::\n\n\nWhat would be more interesting, however, would be to provide outcomes for the predicted standard deviation, or the exponentiated mean:\n\n::: {#211b5853 .cell execution_count=8}\n``` {.stata .cell-code code-fold=\"false\"}\nmargins, dydx(*) predict(sigma)  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nAverage marginal effects                                 Number of obs = 1,434\nModel VCE: OIM\n\nExpression: E(sigma|X), predict(sigma)\ndy/dx wrt:  educ exper 1.female\n\n------------------------------------------------------------------------------\n             |            Delta-method\n             |      dy/dx   std. err.      z    P>|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        educ |  -.0161816   .0031133    -5.20   0.000    -.0222836   -.0100796\n       exper |   -.007517    .000774    -9.71   0.000    -.0090341       -.006\n    1.female |   .0938119   .0175522     5.34   0.000     .0594102    .1282136\n------------------------------------------------------------------------------\nNote: dy/dx for factor levels is the discrete change from the base level.\n```\n:::\n:::\n\n\n::: {#9df7e8a1 .cell execution_count=9}\n``` {.stata .cell-code code-fold=\"false\"}\nmargins, dydx(*) predict(emean)  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nAverage marginal effects                                 Number of obs = 1,434\nModel VCE: OIM\n\nExpression: E(exp(Y)|X), predict(emean)\ndy/dx wrt:  educ exper 1.female\n\n------------------------------------------------------------------------------\n             |            Delta-method\n             |      dy/dx   std. err.      z    P>|z|     [95% conf. interval]\n-------------+----------------------------------------------------------------\n        educ |   2.175891    .169221    12.86   0.000     1.844224    2.507558\n       exper |    .236423   .0394785     5.99   0.000     .1590466    .3137995\n    1.female |   -2.27482   .8226334    -2.77   0.006    -3.887152   -.6624884\n------------------------------------------------------------------------------\nNote: dy/dx for factor levels is the discrete change from the base level.\n```\n:::\n:::\n\n\nSo how do we interpret the results?. Here one possibility:\n\nEach additional year of education increases wages by 7.4%, however, as education increases the dispersion of wages decreases. In terms of actual dollar change, in average, that additional year of education translates in a 2.17$ per hour increase.\n\n## Conclusions\n\nThe purpose of this small article was to walk you through how to use -ml- for the estimation of a simple linear regression. \n\nIn addition, it also introduces you to creating a program that will allow you to use `margins`, when you have a specific outcome in mind, that is not currently available in the command you are interested in using.\n\nHope you find it useful. \n\nComments and question welcome!\n\n",
    "supporting": [
      "stata_do3_files\\figure-html"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}