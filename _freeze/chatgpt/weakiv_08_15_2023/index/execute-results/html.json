{
  "hash": "c3b89635858d8114ccbaf4692737aa63",
  "result": {
    "markdown": "---\ntitle: \"Weak IV: And the problem of Inference\"\ndescription: \"Using a Small Simulation, and based on current research, I ilustrate why F=10, is not enough for inference. \"\nauthor: \"Fernando Rios-Avila\"\ndate: \"8/15/2023\"\ncategories: \n    - Stata\n    - Programming\n    - Econometrics\n    - Weak IV\ndraft: false\nbibliography: ref.bib\n---\n\n## $F \\geq 10 \\rightarrow$ Strong instrument! (or is it?)\n\nIf you are \"old-school\" like me, and you are using instrumental variables, you probably are still relying on the rule thumb of using and $F \\geq 10$ to Judge if an instrument is strong enough to proceed and do statistical inference.\n\nThis \"critical\" value was constructed based on the research by @Staiger_stock_1997 and @stock_yogo2005, and is still included in introductory econometric textbooks, and thought in econometric courses. This are said to be valid in cases where there is no heteroskedasticity in the model. \n\nAs described in Wooldridge's ***\"Introductory Econometrics: A Modern Approach\" 7e***, if models are heteroskedastic, it makes sense that more strict requirements are needed to indicate one has a strong Instrument. Specifically, he cites work by @olea_pflueger2013 who suggest that one might need an $F\\geq 20$ to ensure instruments are sufficiently strong.\n\nIn @lee2022, however, the bar to judge an instrument strong has been raised even higher. What they suggest is that one must consider the joint distribution of the first stage \"F-stat\" statistic and second stage \"t-stat\", to make any inference judgements. Specifically, the authors indicate that, in order to use \"standard\" critical values to judge significance in second stage models (say the 1.96 for and $\\alpha=5\\%$), one should have an F-statistic of at least 104.7!. Alternatively, if we keep using an $F=10$, the t-stat critical value should be at least 3.43. \n\n## How bad is the problem?\n\nWhile I was perplex at first regarding the \"new\" requirements for a high \"F-stat\", I also understood that this problem was important. Because of this, I decided to do a small simulation study to see how bad the problem was in terms of inference, using different levels of Instruments strength. Let me show you how I did this, and what it tells me in regards to previous beliefs about the $F\\geq 10$ rule. \n\nBottom line, in my design, an $E(F)=10$ is not enough to judge an instrument to be strong enough to guarantee the distribution of the coefficient of interest follows a normal distribution. And, if the distribution of such coefficient is not normal, then standard \"t-statistics\" may be inappropiate when making statistical inference.\n\n## Setup\n\nFor this simulation, I will use a very simple structure that considers a single endogenous variable and a single instrument, without any other controls. \n\n- First, The common Error: To simulate endogeneity, I will assume there is a common unobserved factor $e$ that affects the endogenous variable $x$ and outcome $y$. This unobserved error is assumed to follow a standardized normal distribution.\n\n$$e\\sim N(0,1)$$\n\n- The instrument: The instrument will be a completely independent variable that also follows a standardized normal distribution. \n\n$$z\\sim N(0,1)$$\n\n- The endogenous variable: This variable will be created by adding the endogenous common error $e$, the instrument $z$ and a random error $u_x$. To control the strength of the instrument, the endogenous variable $x$ is defined as:\n\n$$x=1 + z + (e+u_x)*\\sqrt{2\\frac{N}{F}}$$\n\nwhere $N$ is the number of observations, and $F$ is the Expected Strength of the instrument. \n\n- The dependent variable: It will combine the common error and a random standardize normal distributed error, and assume $x$ has no explanatory power. The common error $e$ and the standardized  normal distributed error $u_y$ are scaled so the combined error has a variance of 1.\n\n$$y = 1 + (e + u_y)*\\sqrt{2}$$\n\nThe simulation is run 100'000 times, with a sample of 500 observations each, using various levels of \"F-statistics\": 5, 10, 20, 40, 80 and 160. To speed up the simulation excercise, I use `parallel`, a community-contributed command written @VegaYon2019. You can find the latest version of it on their [github](https://github.com/gvegayon/parallel).\n\nThe code for the simulation program is as follows:\n\n```stata\nprogram simx, eclass\n\tclear\n\tlocal N `1'\n\tlocal F `2'\n\tlocal sig = sqrt(`N'/ `F')\n\tset obs `N'\n\tgen e = rnormal()\n\tgen z = rnormal() \n\tgen x = 1 + z + (e+rnormal())*sqrt(.5)*`sig'\n \tgen y = 1 + ( e + rnormal())*sqrt(.5)\n\treg x z, \n\tmatrix b=(_b[z]/_se[z])^2\n\tivregress 2sls  y (x=z), \n\tmatrix b=b,_b[x],_b[x]/_se[x]\n\tereturn post b\nend\n```\n\nand the simulation itself can be run using:\n\n```stata\nnet install parallel, from(https://raw.github.com/gvegayon/parallel/stable/) replace\nmata mata mlib index\n** Initializes number of \"Stata\" instances\nparallel initialize 17\n** Some tempfiles to store the simulations\ntempfile f0 f1 f2 f3 f4 f5\n** A loop for the simulations\nforvalues i = 0/5 {\n    local j = 5*2^`i'\n    parallel sim, reps(100000): simx 500 `j'\n    gen F=`j'\n    save `f`i''\n}\n \n** Append and rename\nclear \nappend using `f0'\nappend using `f1'\nappend using `f2'\nappend using `f3'\nappend using `f4'\nappend using `f5'\n\nren (_b_c1 _b_c2 _b_c3 F) (f_stat b_coef t_stat FF)\n```\n\nIf you are interested in the data, it can be downloaded from [here](weakiv.dta). It is a `Stata` file with 4 variables and 60k observations.\n\n## Results\n\nFirst, to make sure data was created correctly, we can do a quick summary statistics of the F-statistic of the first stage regression.\n\n::: {#84bcbfc7 .cell execution_count=1}\n``` {.stata .cell-code}\nuse weakiv, clear\ntabstat f_stat , by(FF) stats(mean median)\n```\n\n::: {.cell-output .cell-output-display}\n```{=html}\n<style>div.jp-Notebook .datagrid-container {min-height: 448px; }</style>\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSummary for variables: f_stat\nGroup variable: FF \n\n      FF |      Mean       p50\n---------+--------------------\n       5 |  6.012032  4.989151\n      10 |  11.03701  10.01228\n      20 |   21.0688  19.97883\n      40 |  41.13833  39.95357\n      80 |  81.26734  79.84747\n     160 |  161.4196  159.6645\n---------+--------------------\n   Total |  53.65718  29.36334\n------------------------------\n```\n:::\n:::\n\n\nThe mean is a bit higher than the intended F-Statistic, whereas the median is closer. Both statistics suggesting simulations were created as intended.  \n\n::: {#dcc70c98 .cell execution_count=2}\n``` {.stata .cell-code}\nset scheme white2\ncolor_style tableau\njoy_plot f_stat, by(FF) gap0 color(%50) alegend xtitle(\"F-stat\") xline(10 20 100)\n```\n\n::: {.cell-output .cell-output-display}\n![F-Statistics Distribution](index_files/figure-html/cell-3-output-1.png){fig-align='center'}\n:::\n:::\n\n\nWe can also see the distribution of the F-statistics across all simulations. \n\nWhat about the endogenous variable coefficient? \n\nWhile we could examine the coefficient themselves, I find it more useful to examine the distribution of the t-statistics in the second Stage.\n\n::: {#1e7ecc3f .cell execution_count=3}\n``` {.stata .cell-code}\ntwo kdensity t_stat || function y = normalden(x) , range(-3 3) , by(FF, note(\"\")) legend(order(1 \"T-stat distribution\" 2 \"Normal\") cols(2)) xline(-1.96 1.96)\ngraph export fig1.png, replace width(1000) \n\ntwo kdensity t_stat if f_stat>10 || function y = normalden(x) , range(-3 3) , by(FF, note(\"\")) legend(order(1 \"T-stat distribution\" 2 \"Normal\") cols(2)) xline(-1.96 1.96)\ngraph export fig2.png, replace width(1000) \n```\n:::\n\n\n![T-Stat distribution by E(F)](fig1.png){fig-pos=\"center\" #fig-fig1 width=80%}\n\nWhat we see from @fig-fig1 is that the distribution of the t-statistic is not consistent with a normal distribution. For and $F\\leq 40$, there is a clear discrepancy between the normal distribution (orange) and the empirical t-stat distribution (blue). As consequence, when coefficients are possitive, it is more likely to reject the null hypothesis, but also under-reject when the coefficients are negative. \n\nOnce we reach an F-statistic of at least 80 and 160, the difference between the normal distribution and the t-statistic empirical distribution dissapears. Lesson, if your F-stat is \"low\", perhaps using standard distributions may be innapropriate.\n\nOne problem with the results in @fig-fig1 was that when $E(F)$ is low, there are many instances where the F-distribution is less than 10. One may say that is the reason why the distribution is skew in @fig-fig1. A simple way to avoid this is by ploting the same information, but restricting F-statistics to be larger than 10.\n\n![T-Stat distribution by E(F) if F>10](fig2.png){fig-pos=\"center\" #fig-fig2 width=80%}\n\nUnfortunately, the situation is much worse. By constraining the F-statistic to be larger than 10, we are doing the equivalent of p-hacking (F hacking?), which further distorts the distribution of the endogenous variable. While it looks a bit more normal (distributed), we can see now that it over rejects the null hypothesis, if the true F-statistic was, in fact, lower. You can call this evidence of biased estimations.\n\n## Conclusions\n\nThis note was prepared with the intention of showing in class the consequences of weak IV's. While I knew that this was an important problem, it was not completely clear what would the consequences in terms of distribution of the coefficient of interest would be.\n\nAlthough this simulation is rather limited, it clearly shows problems of using weak instrumental variables (even when using the well known \"rule of 10\"). When the instrument is weak, even if its completely exogenous, the distribution of the endogenous variable coefficient will not be normal. Thus, further steps may be needed for constructing appropriate Confidence intervals.\n\nIs everything lost? Perhaps not. In `Stata`, there is the community-contributed command `weakiv` (ssc install weakiv). This command construct alternative CI that take into account the presence of weak instrumental variables reporting adjusted CI. They seem to be closer to what I expect, based on this simulations.\n\n## Extra\n\nOk, so while you do simulations like this, sometimes, you find very interesting results. Some worth exploring.\n\nWhat did I see (you may ask)? First, let me concentrate only on the cases with \"stronger\" IVs. In particular those with an $E(F)\\leq 80$. None of the F-statistics is less than 10 across all simulations in this case.\n\nSecond, because the F-Statistics have different ranges, I will standardize them across groups. This will make it easier to compare scatter plots.\n\n::: {#e70552a5 .cell execution_count=4}\n``` {.stata .cell-code}\n** Keeping only FF>=80\nqui {\n    keep if FF>=80\n    gen f_stat2=.\n    foreach i in 80 160 {\n        sum f_stat if FF==`i'\n        replace f_stat2 = (f_stat-FF)/r(sd) if FF==`i'\n    }\n}\n\ntwo scatter t_stat  f_stat2 , by(FF , col(3) note(\"\")) ysize(5) xsize(10) ///\n    ytitle(T-stat) xtitle(\"Standardized F-Stat\")\ngraph export fig3.png, replace width(1000)\n```\n:::\n\n\n![T-Stat vs SF-Stat](fig3.png){fig-pos=\"center\" #fig-fig3 width=80%}\n\nWhat I see in @fig-fig3 is that higher F-Stats in the first Stage seem to increase the likelihood of the t-value to be positive and significant. Whereas lower F-stats are associated with the opposite (but to a lesser extent possibly due to simulation design). \n\n::: {#ae0c9901 .cell execution_count=5}\n``` {.stata .cell-code}\ntwo (kdensity t_stat if inrange(f_stat2,-.65,.7)) ///\n    (kdensity t_stat if f_stat2<-.65) ///\n    (kdensity t_stat if f_stat2>.7) , ///\n    legend(order(1 \"sF-Stat near 0\" 2 \"sF-Stat<25thp\" 3 \"Sf-Stat>75thp\")) ///\n    xtitle(\"t-Statistic Distribution\") ytitle(\"Density\")\ngraph export fig4.png, replace  width(1000) \ntwo (kdensity b_coef if inrange(f_stat2,-.65,.7)) ///\n    (kdensity b_coef if f_stat2<-.65) ///\n    (kdensity b_coef if f_stat2>.7) , ///\n    legend(order(1 \"sF-Stat near 0\" 2 \"sF-Stat<25thp\" 3 \"Sf-Stat>75thp\")) ///\n    xtitle(\"Coefficient Distribution\") ytitle(\"Density\")\ngraph export fig5.png, replace  width(1000)    \n```\n:::\n\n\n::: {#fig-fig4 layout-ncol=2}\n\n![t-Stat Distribution](fig4.png){#fig-fig4a}\n\n![Coefficient Distribution](fig5.png){#fig-fig4b}\n\nDistribution based on Standardized F-Statistic\n:::\n\n@fig-fig4 shows the distribution of both the t-statistic and the coefficient of the endogenous variables for three groups. Observations where the F-statistic is between the 25th and 75th percentile of the distribution (Thus close to the E(F)), and observations for the top (above 75th percentile) and bottom (below 25th percentile) of the distribution. This is similar to the previous conjecture. Even if the instrument is \"strong\", if the sample F-statistic is too high or low compared to the E(F), inference may be biased.\n\nThis is just conjecture, however, it may be the case that IV's are more difficult to trust that I previously expected. If your first stage has a high F-Statistic, it may be worth asking:\n\n> is this F-statistic larger than expected?\n\nIf the answer is yes, then you are likely to be over (or under) stating your coefficients.\n\nIf the F-statistic is just as large as expected. Then we may be able to trust the estimated coefficients. \n\n\n# References\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}